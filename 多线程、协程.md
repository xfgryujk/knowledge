# 线程
线程是分配CPU资源的单位，不同的线程可以在不同的CPU上同时执行


## 线程安全
当多个线程同时操作同一资源（变量）时，会导致竞争条件（race condition）的问题——系统的行为取决于其他不可控事件的发生顺序或时机

比如两个线程同时执行`i++`，这其实分成3步：

1. 从内存读取i的值到寄存器
2. 在寄存器中计算`i + 1`的值
3. 把结果写回内存

假设i的初始值是0，两个线程会同时读取到0，然后计算出1，最后写回内存的值是1。但`i++`执行了2次，最后i的值应该是2

如果一个过程在多个线程同时执行时，保证它的逻辑是正确的，那么它是线程安全的

保证线程安全的方法：

* 不共享：每个线程使用不同的变量，不要操作同一个变量。通常可以用`thread_local`实现
* 不可变：只读取变量，不修改
* 使用线程同步保证过程是串行化的：保证同时只能有一个线程修改变量


## CPU缓存一致性
[参考](https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#cpu-cache-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5)

每个CPU核心有自己的L1、L2缓存。如果一个CPU修改了缓存，但是没写入内存，然后另一个CPU读取这个地址，就会读取到旧值，导致缓存不一致

解决缓存一致性问题要保证这两点：

* 写传播：CPU修改自己缓存的数据时，要通知其他CPU
* 事务串行化：每个CPU收到其他CPU通知的操作顺序必须是一致的

### MESI协议
[参考](https://en.wikipedia.org/wiki/MESI_protocol)

现在CPU保证缓存一致性一般使用MESI协议。MESI是缓存的4个状态的开头字母：

* Modified（已修改）：缓存已修改，但还没写到内存里
* Exclusive（独占）：缓存和内存一致，只有本CPU有这个缓存行的数据，其他CPU没有
* Shared（共享）：缓存和内存一致，但是有多个CPU有这个缓存行的数据
* Invalidated（已失效）：相当于没有这个缓存

这几个状态会根据本CPU对缓存的读写、总线嗅探器指出的其他CPU的读写而改变

当CPU写入S状态的缓存时，要通知其他CPU使它们的缓存失效（所有权广播，Request For Ownership）。当缓存状态是M、E的时候，写入缓存不需要通知其他CPU使缓存失效，这减少了总线的压力

### 伪共享
CPU1要修改变量A，CPU2要修改变量B，但是变量A和B地址太近了，在同一个缓存行中，这个缓存行就是伪共享的。伪共享会导致缓存频繁失效，影响性能

解决伪共享问题：

* C++中可以用`alignas(64)`设置内存对齐要求，使A、B变量在不同的缓存行。
* 其他语言可以在A、B变量之间添加填充变量


## 原子操作
CPU提供了CAS（Compare-And-Swap）操作来实现原子操作，CPU会保证这个过程不被打断

比如x86的`CMPXCHG`：比较交换指令，第一操作数（当前值）先和AL/AX/EAX（期待的旧值）比较，如果相等则ZF置1，且把第二操作数（新的值）赋值给第一操作数；否则ZF置0，把第一操作数（当前值）赋给AL/AX/EAX

程序可以判断CAS是否成功，如果失败了，根据当前值再计算出新的值，再重试CAS，直到成功

所有的线程同步机制都是基于CPU提供的原子操作的。比如可以在用户态实现自旋锁：将变量值为1视为上锁了，如果当前值为0则用CAS尝试设置为1，如果失败了或者值已经是1则循环重试

CPU怎么保证原子操作的：

1. 首先要保证不被硬件中断打断了原子操作
2. 还要保证其他CPU这时不会操作对应的地址：
    * x86早期的CPU会向总线发出锁定信号，使其他CPU不能使用总线，只有自己能用。这是很影响性能的，因为没有区分地址、读写请求
    * 新版的CPU的只有地址跨缓存行时才会锁总线。如果没有跨缓存行且地址已经被缓存了，只需要在CPU内部修改就行了，缓存一致性机制会保证操作是原子的，这种操作也被称为缓存锁

        > 7.1.4 Effects of a LOCK Operation on Internal Processor Caches.
        >
        > For the Intel486 and Pentium processors, the LOCK# signal is always asserted on the bus during a LOCK operation, even if the area of memory being locked is cached in the processor.
        >
        > For the P6 and more recent processor families, if the area of memory being locked during a LOCK operation is cached in the processor that is performing the LOCK operation as write-back memory and is completely contained in a cache line, the processor may not assert the LOCK# signal on the bus. Instead, it will modify the memory location internally and allow \[its\] cache coherency mechanism to insure that the operation is carried out atomically. This operation is called "cache locking." The cache coherency mechanism automatically prevents two or more processors that have the same area of memory from simultaneously modifying data in that area. (emphasis added)

CAS缺点：

* ABA问题，即变量的值由A变成B，再变成A，此时CAS会成功。一种解决方法是加上版本，比如原来32位整数改用64位整数，高32位表示版本，CAS的时候把版本和值一起修改
* 如果经常失败那么需要不停重试，浪费CPU
* 只能保证一个变量的原子性


## POSIX线程同步方式
### 互斥锁
互斥锁同一时间只能有一个线程锁定，其他线程再次上锁时会阻塞，直到锁被释放，这样保证了同时只有一个线程能访问资源

和自旋锁相比：比自旋锁更重量级，因为需要系统调用。但是比自旋锁CPU占用低，因为阻塞的时候线程进入休眠，不会消耗CPU资源

### 读写锁
因为只读的过程同时执行是安全的，只读的过程之间不需要互斥。读写锁可以使只读的线程不会互相阻塞，而读和写、写和写会互相阻塞

读写锁适用于读多写少的情况

### 条件变量
条件变量可以阻塞线程，直到其它线程修改了一些共享变量（条件），并通知唤醒线程。它要配合锁使用，这个锁是用来保护共享变量的，而不是保护条件变量本身

要等待条件的线程：

1. 获得互斥锁
2. 检查条件
3. 如果条件不成立，调用`pthread_cond_wait`，会释放互斥锁并阻塞等待通知
4. 被唤醒后会获得互斥锁，这时可能是被虚假唤醒的，要再次检查条件，如果条件不成立则再次`pthread_cond_wait`

要修改条件并发通知的线程：

1. 获得互斥锁
2. 修改条件
3. 发送通知（这一步不需要持有互斥锁），调用`pthread_cond_signal`或`pthread_cond_broadcast`

虚假唤醒的原因：

* 可能是`pthread_cond_wait`在系统调用的时候收到了信号，系统调用被打断了
* 可能一次唤醒了多个线程，第一个线程先拿到互斥锁，修改了条件，然后第二个线程拿到互斥锁时发现条件不成立了
* 还跟操作系统底层实现有关，[参考](https://linux.die.net/man/3/pthread_cond_signal)

### 信号量
信号量用来控制同时访问资源的线程数量，允许同时有多个线程访问，但数量不能超过一定量。它不是用来保证线程安全的，而是用来控制并发数的。也可以用于发送提醒，它有比条件变量更好的性能

通过两个原子操作的系统调用来控制信号量：

* P操作：将信号量的值-1，如果< 0，则说明当前使用资源的线程太多，阻塞当前线程
* V操作：将信号量的值+1，如果<= 0，则说明有其他线程正在等待，唤醒一个等待中的线程


## 死锁
死锁是指每个线程都在等待其他线程释放资源，在没有外力干涉的情况下，它们会一直互相等待，无法继续运行

产生条件：

* 互斥：同时最多只能有一个线程使用资源
* 持有并等待：线程在等待获取其他资源的同时不会释放自己已经持有的资源
* 不可剥夺：在线程释放资源之前，资源不能被其他线程获取
* 环路等待：获取资源的顺序形成了环路

避免死锁只要破坏上面任意一个条件即可。最常用的方法是规定获取资源的顺序，比如必须先获取资源1再获取资源2，不能先获取资源2再获取资源1。C++的`scoped_lock`是获取任何锁失败时就释放掉前面获取的锁，然后全部重试


# 协程
协程是可暂停执行，然后可以从暂停点恢复执行的函数。协程比线程早诞生，最早是为了实现多任务，异步编程流行之后又用于简化异步编程

协程和线程的区别：

* 协程在用户态调度，线程由内核调度
* 不同线程可以同时执行，而运行在同一个线程的不同协程是交替执行的
* 协程是协作式多任务，线程是抢占式多任务。这意味着协程要显式切换上下文，而不会在任意位置隐式切换

优点：

* 与线程相比，切换上下文的成本更小，可以在用户态实现
* 运行在同一个线程的协程可以安全地使用同一个资源，而不需要加锁等同步方式
* 与回调相比，可以用和同步编程类似的代码写异步编程，不用分割成多个函数，避免回调地狱
* 与回调相比，上下文全部存储在局部变量里，不用考虑怎么传递上下文

缺点：

* 不能充分利用多核CPU，适用于IO密集型的任务，不适用于计算密集型的任务
* 必须使用异步的系统调用，如果使用了同步系统调用阻塞了，同一个线程上的所有协程都会阻塞
* 因为看起来像同步的代码，容易忽略在暂停点之后，前面的条件可能不成立了。比如C++中在暂停点之前有效的指针，在暂停点之后可能就无效了

协程如何简化异步编程：启动一个异步操作，指定在回调中唤醒本协程，然后本协程进入休眠，让出控制权


## 分类
有栈协程、无栈协程：

* 有栈协程：
    * 有栈是指暂停的时候要保持栈的结构
    * 所有局部变量存储在栈上
    * 协程的栈和“主协程”的栈不是同一个，底层通过修改SP寄存器切换栈
    * 协程可以在栈帧嵌套任意深度时切换
    * 有栈协程没有传染性，还是按照同步调用写，反正调用到需要切换的函数也是可以切换的
* 无栈协程：
    * 无栈是指暂停的时候不需要栈
    * 存储期跨越暂停点的局部变量存储在堆上
    * 协程的栈和“主协程”的栈是同一个，“主协程”切换到协程就是普通的函数调用，会创建一个栈帧；协程切换回“主协程”就是普通的`return`，回到上一个栈帧。因此无栈协程像一个状态机：

        ```c++
        void coro(Context& ctx) { // 存储期跨越暂停点的局部变量存储在ctx里
            switch (ctx.step) { // 上次执行到哪个暂停点了
            case 0:
                // 第一次执行...
                // 暂停并切换回上一层
                ctx.step++;
                return;
            case 1:
                // 第二次恢复执行...
                // 暂停并切换回上一层
                ctx.step++;
                return;
            }
        }
        ```

    * 只有在顶级栈帧时能切换，不能调用一个同步函数，然后在函数内部切换
    * 无栈协程具有传染性，想要等待别的协程，自己也必须是无栈协程。因此支持无栈协程的语言一般提供了`async`、`await`关键词，只有在`async`函数中才能使用`await`等待

优点、缺点：

* 性能：无栈协程切换更快，需要的机器周期更少。无栈协程对CPU指令预测更友好，因为就是普通的函数调用和`return`，而有栈协程会手动修改栈顶寄存器，使CPU预测失败
* 空间：无栈协程占用的空间更小，因为一般会有编译器支持，只把存储期跨越暂停点的局部变量存储在堆上。而有栈协程不能确定需要多大的栈，创建时要分配一个足够大的栈，而且暂停时会保持栈
* 侵入性、兼容性：有栈协程的侵入度更低，而且可以支持旧代码，因为不需要显式的`async`、`await`，有栈协程就是按同步调用写的

Python、JavaScript、C++20、C#提供的是无栈协程，Go提供的是有栈协程

对称协程、非对称协程：

* 对称协程：
    * 只提供了一个控制权转移操作`yield`。`yield`之后控制权转移给调度器，由调度器决定接下来调度哪个协程
    * 协程之间地位相等，应该通过通信的方式传递值
    * Python的`async`函数是对称协程，它是通过`add_done_callback`来获取目标协程返回值的

        ```python
        async def f():
            # 创建g协程，通过add_done_callback让g协程结束后唤醒自己并传递返回值，然后f协程休眠，控制权转移给调度器
            res = await g()
        ```

* 非对称协程：
    * 提供了两个控制权转移操作`resume`、`yield`。`resume`用于调度指定的协程。`yield`将控制权转移给上一层，最顶层才是调度器
    * 协程之间的关系像调用者和被调用者，可以简单地给上一层传递产出的值
    * Python的生成器函数是非对称协程，它的控制权转移到上一层时就能获取到产出的值

        ```python
        def f():
            gen = range(10)
            for res in gen:  # 调度gen协程，gen暂停时控制权转移给f
                yield res  # f协程暂停，控制权转移给上一层
            # 也可以用 yield from gen 简化这段代码，这时候看起来就像对称协程
        ```

这两种协程具有相同的表达能力，没有优劣之分。但是异步编程通常用对称协程，而生成器通常用非对称协程，这样实现比较简单
